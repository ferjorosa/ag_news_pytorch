{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "PyTorch tutorial on text classification for the AG news data. \n",
    "\n",
    "The AG's news topic classification dataset is constructed by choosing 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600.\n",
    "\n",
    "The classes are the following:\n",
    "\n",
    "* World\n",
    "* Sports\n",
    "* Business\n",
    "* Sci/Tec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Load the data in raw form\n",
    "\n",
    "We download the AG_NEWS data from `torchtext.datasets` and create a simple `DataLoader` to better understand the internal format of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.datasets_utils._RawTextIterableDataset'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Load the original data in form [tensor_label, (text,)]\n",
    "raw_iterable_dataset = AG_NEWS(split='train')\n",
    "\n",
    "# Show the type of the IterableDataset\n",
    "print(type(raw_iterable_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3]), (\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",)]\n",
      "[tensor([3]), ('Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.',)]\n"
     ]
    }
   ],
   "source": [
    "# Create a simple dataLoader and print the first two dataInstances to better understand the internal format\n",
    "raw_dataloader = DataLoader(raw_iterable_dataset)\n",
    "for i in range(0,2):\n",
    "    print(next(iter(raw_dataloader)))\n",
    "\n",
    "# Note: if we run this example, we have to then re-load the data, due to the use of an iteration \n",
    "# (torchtext.vocab was giving me issues with a previously iterated dataset)\n",
    "# maybe an IterableDataSet can only be iterated once\n",
    "raw_iterable_dataset = AG_NEWS(split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Preprocessing functions\n",
    "\n",
    "Use some of the basic components of `torchtext` to preprocess the raw IterableDataset:\n",
    "* tokenizer\n",
    "* vocabulary builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95811"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# we use the basic english tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# method for applying the tokenizer on each data instance of the IterableDataset and returning the result as an iterator\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# It builds the vocabulary from the iterator returned by `yield_tokens()`\n",
    "vocab = build_vocab_from_iterator(yield_tokens(raw_iterable_dataset), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example for understanding the result of tokenizer and vocabulary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n",
      "[431, 425, 1, 1605, 14838, 113, 66, 2, 848, 13, 27, 14, 27, 15, 50725, 3, 431, 374, 16, 9, 67507, 6, 52258, 3, 42, 4009, 783, 325, 1]\n"
     ]
    }
   ],
   "source": [
    "test_string = \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\"\n",
    "test_string_tokenized = tokenizer(test_string) #  output in list format (makes sense because its contents are currently strings)\n",
    "test_string_indexed = vocab(test_string_tokenized) #  output in list format (not tensor)\n",
    "\n",
    "print(test_string)\n",
    "print(test_string_tokenized)\n",
    "print(test_string_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define the two lambda functions that will be used as preprocessing steps when iterating over the data. These function will act as our \"pipeline\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text pipeline converts a text string into a list of integers based on the lookup table defined in the vocabulary. The label pipeline converts the label into integers. \n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[475, 21, 2, 30, 5297]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(text_pipeline('here is the an example'))\n",
    "print(label_pipeline(\"10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - DataLoader and iterator\n",
    "\n",
    "In order to learn our model, we need the dataset to be in `torch.utils.data.DataLoader` form. The format of this DataLoader is going to be influenced by our learning purpose. In this example, we want to do text classification where the text inputs do not have the same length. Therefore, the text entries in the original data batch input are packed into a list and concatenated as a single tensor for the input of `nn.EmbeddingBag`. The **offset** is a tensor of delimiters to represent the beginning index of the individual sequence in the text tensor. Label is a tensor saving the labels of individual text entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0] # offset list is initialized with the value 0, because it is the index of the beginning of the first sentence in the batch\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "train_iter = AG_NEWS(split='train')\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better understanding of the input difference between `nn.Embedding` and `nn.EmbeddingBag`, consider the following image (ignore the last part, it is simply showing common applications of these layers):\n",
    "\n",
    "<img src=\"notebook_images/regular_embedding_vs_embedding_bag_diagram.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I considered this simple example to see what happened inside the DataLoader. Interestingly,\n",
    "# each time the DataLoader was iterated, it returned a different set of objects in the batch,\n",
    "# even if the DataLoader was created with shuffle=False\n",
    "\n",
    "# for X in dataloader:\n",
    "#     print(X[1].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Model\n",
    "\n",
    "The model is composed of the `nn.EmbeddingBag` layer plus a `nn.LinearLayer` for the classification purpose. `nn.EmbeddingBag` computes by default the mean value of a “bag” of embeddings. Although the text entries here have different lengths, nn.EmbeddingBag module requires no padding here since the text lengths are saved in offsets.\n",
    "\n",
    "Additionally, since `nn.EmbeddingBag` accumulates the average across the embeddings on the fly, it can enhance the performance and memory efficiency to process a sequence of tensors.\n",
    "\n",
    "<img src=\"notebook_images/basic_model.png\" width=600>\n",
    "\n",
    "The output function for this example would either be a Softmax or a hierarchical Softmax. In this case, we are going to consider the Softmax. In PyTorch, when doing classification, we have the flexibility of manualyapplying the output function or not. It will depend on our selection of the loss function (the first time it seems a bit counterintuitive):\n",
    "\n",
    "* If we use `nn.CrossEntropyLoss` as our loss function, it will automatically apply the logSoftmax function to the neural network output.\n",
    "* If we use `nn.NLLLoss()` as our loss function, it is necessary that we establish a LogSoftmax activation function at the end of our model (return of the `forward()` method)\n",
    "\n",
    "In this case we are going to choose the first option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in the data: 4\n",
      "Number of hidden dimensions (both embedding and linear layers): 64\n",
      "Size of vocabulary: 95811\n"
     ]
    }
   ],
   "source": [
    "raw_iterable_dataset = AG_NEWS(split='train')\n",
    "num_class = len(set([label for (label, text) in raw_iterable_dataset]))\n",
    "vocab_size = len(vocab)\n",
    "num_hid = 64\n",
    "model = TextClassificationModel(vocab_size, num_hid, num_class).to(device)\n",
    "\n",
    "print(\"Number of classes in the data: \" + str(num_class))\n",
    "print(\"Number of hidden dimensions (both embedding and linear layers): \" + str(num_hid))\n",
    "print(\"Size of vocabulary: \" + str(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Training\n",
    "\n",
    "We first define the `train()` and `evaluate()` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader, criterion, optimizer, current_epoch):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(current_epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we consider the splitted data (train/test) and define the validation dataset with 5% of the training data instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 5 # number of epochs\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 1782 batches | accuracy    0.688\n",
      "| epoch   1 |  1000/ 1782 batches | accuracy    0.855\n",
      "| epoch   1 |  1500/ 1782 batches | accuracy    0.880\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 13.27s | valid accuracy    0.880 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 1782 batches | accuracy    0.897\n",
      "| epoch   2 |  1000/ 1782 batches | accuracy    0.902\n",
      "| epoch   2 |  1500/ 1782 batches | accuracy    0.902\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 13.92s | valid accuracy    0.896 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 1782 batches | accuracy    0.918\n",
      "| epoch   3 |  1000/ 1782 batches | accuracy    0.912\n",
      "| epoch   3 |  1500/ 1782 batches | accuracy    0.914\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 13.78s | valid accuracy    0.899 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 1782 batches | accuracy    0.926\n",
      "| epoch   4 |  1000/ 1782 batches | accuracy    0.925\n",
      "| epoch   4 |  1500/ 1782 batches | accuracy    0.922\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 14.14s | valid accuracy    0.903 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 1782 batches | accuracy    0.930\n",
      "| epoch   5 |  1000/ 1782 batches | accuracy    0.929\n",
      "| epoch   5 |  1500/ 1782 batches | accuracy    0.929\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 13.45s | valid accuracy    0.899 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader, criterion, optimizer, epoch)\n",
    "    accu_val = evaluate(valid_dataloader, criterion)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Evaluation\n",
    "\n",
    "We check the accuracy of our model on the test dataset. It is important to remember that since SGD is stochastic and we also have shuffle=True, the accuracy on both the validation and test datasets may vary on training executions (obviously it should not change on evaluation if the model is not re-learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy    0.906\n"
     ]
    }
   ],
   "source": [
    "accu_test = evaluate(test_dataloader, criterion)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Inference example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sports news\n"
     ]
    }
   ],
   "source": [
    "ag_news_label = {1: \"World\",\n",
    "                 2: \"Sports\",\n",
    "                 3: \"Business\",\n",
    "                 4: \"Sci/Tec\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "ex_text_str = \"MEMPHIS, Tenn. - Four days ago, Jon Rahm was \\\n",
    "    enduring the season's worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday's first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he'd never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7c091c86dcdede3a40e42e3736e7ffa1e82d65bcd3790e75d25b0e8ed3294a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
